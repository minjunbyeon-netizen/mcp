#!/usr/bin/env python3
"""
í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ë¸”ë¡œê·¸ ê¸€ ìƒì„±ê¸°
ì‚¬ìš©ë²•: python run_blog_generator.py
"""

import sys
import os
import json
import io
import threading
import time
import subprocess
from datetime import datetime
from pathlib import Path

# Windows í„°ë¯¸ë„ UTF-8 ì¶œë ¥ ì„¤ì • (ì¤‘ë³µ ë˜í•‘ ë°©ì§€)
if sys.platform == 'win32' and not isinstance(sys.stdout, io.TextIOWrapper):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# mcp_config.jsonì—ì„œ API í‚¤ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

config_path = Path(__file__).parent / "mcp_config.json"
if config_path.exists() and not os.getenv("GEMINI_API_KEY"):
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
        api_key = config.get("mcpServers", {}).get("content-automation", {}).get("env", {}).get("GEMINI_API_KEY")
        if api_key:
            os.environ["GEMINI_API_KEY"] = api_key

from google import genai
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# í˜ë¥´ì†Œë‚˜ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
from persona_version_manager import (
    load_latest_persona,
    create_upgraded_version,
    get_feedback_history,
    save_feedback_history,
    compare_versions,
    generate_default_blog_config
)

# ë‹¤ì¤‘ íŒŒì¼ í˜•ì‹ ì§€ì›
import pdfplumber
from PIL import Image
import base64

# HWP ì§€ì› (olefile ì‚¬ìš©)
try:
    import olefile
    import zlib
    HWP_SUPPORTED = True
except ImportError:
    HWP_SUPPORTED = False

# ì§€ì› íŒŒì¼ í™•ì¥ì
SUPPORTED_EXTENSIONS = ['.txt', '.pdf', '.hwp', '.jpg', '.jpeg', '.png']


def extract_text_from_file(file_path: Path) -> str:
    """ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    ext = file_path.suffix.lower()
    
    if ext == '.txt':
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    elif ext == '.pdf':
        text = ""
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    
    elif ext == '.hwp':
        if not HWP_SUPPORTED:
            raise ValueError("HWP ì§€ì›ì„ ìœ„í•´ 'pip install olefile'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        text_parts = []
        try:
            ole = olefile.OleFileIO(str(file_path))
            # í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì°¾ê¸°
            for stream in ole.listdir():
                if 'BodyText' in stream or 'Section' in stream:
                    try:
                        data = ole.openstream(stream).read()
                        # ì••ì¶• í•´ì œ ì‹œë„
                        try:
                            decompressed = zlib.decompress(data, -15)
                            # í•œê¸€ ë””ì½”ë”© ì‹œë„
                            text = decompressed.decode('utf-16-le', errors='ignore')
                            # ì œì–´ ë¬¸ì ì œê±°
                            text = ''.join(c for c in text if c.isprintable() or c in '\n\r\t')
                            if text.strip():
                                text_parts.append(text)
                        except:
                            pass
                    except:
                        pass
            ole.close()
        except Exception as e:
            raise ValueError(f"HWP íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        return "\n".join(text_parts) if text_parts else ""
    
    elif ext in ['.jpg', '.jpeg', '.png']:
        # ì´ë¯¸ì§€ëŠ” Gemini Visionìœ¼ë¡œ ì²˜ë¦¬ (base64 ì¸ì½”ë”©)
        return f"[IMAGE_FILE:{file_path}]"
    
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")


def get_file_type_icon(ext: str) -> str:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì•„ì´ì½˜ ë°˜í™˜"""
    icons = {
        '.txt': 'ğŸ“„ TXT',
        '.pdf': 'ğŸ“• PDF',
        '.hwp': 'ğŸ“˜ HWP',
        '.jpg': 'ğŸ–¼ï¸ JPG',
        '.jpeg': 'ğŸ–¼ï¸ JPEG',
        '.png': 'ğŸ–¼ï¸ PNG',
    }
    return icons.get(ext.lower(), 'ğŸ“ FILE')


def select_press_release():
    """í´ë” ë° íŒŒì¼ ì„ íƒ (ê³µìš© í•¨ìˆ˜)"""
    
    # í•˜ìœ„ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    subfolders = [f for f in INPUT_DIR.iterdir() if f.is_dir()]
    
    # í˜„ì¬ í´ë”ì˜ íŒŒì¼ë„ ê°€ì ¸ì˜¤ê¸°
    root_files = [
        f for f in INPUT_DIR.iterdir() 
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS and f.name.lower() != "readme.txt"
    ]
    
    # í´ë”ê°€ ìˆìœ¼ë©´ ë¨¼ì € í´ë” ì„ íƒ
    if subfolders:
        print("\nğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ í´ë”:")
        print("-" * 50)
        
        # 0ë²ˆ: í˜„ì¬ í´ë” (ë£¨íŠ¸)
        if root_files:
            print(f"  0. [í˜„ì¬ í´ë”] ğŸ“‚ ({len(root_files)}ê°œ íŒŒì¼)")
        
        # í•˜ìœ„ í´ë” ëª©ë¡
        for i, folder in enumerate(subfolders, 1):
            # í´ë” ë‚´ íŒŒì¼ ìˆ˜ ê³„ì‚°
            folder_files = [
                f for f in folder.iterdir() 
                if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS
            ]
            print(f"  {i}. {folder.name} ğŸ“‚ ({len(folder_files)}ê°œ íŒŒì¼)")
        
        print("\nğŸ”¢ í´ë” ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (0: í˜„ì¬ í´ë”):")
        try:
            folder_choice = int(input(">>> ").strip())
            
            if folder_choice == 0:
                if not root_files:
                    print("âŒ í˜„ì¬ í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return None
                target_dir = INPUT_DIR
            elif 1 <= folder_choice <= len(subfolders):
                target_dir = subfolders[folder_choice - 1]
                print(f"\nâœ… ì„ íƒëœ í´ë”: {target_dir.name}")
            else:
                print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
                return None
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return None
    else:
        target_dir = INPUT_DIR
    
    # ì„ íƒëœ í´ë”ì—ì„œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    press_files = [
        f for f in target_dir.iterdir() 
        if f.is_file() and f.suffix.lower() in SUPPORTED_EXTENSIONS and f.name.lower() != "readme.txt"
    ]
    
    if not press_files:
        print("\nâŒ ë³´ë„ìë£Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ğŸ“‚ ì´ í´ë”ì— íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”:")
        print(f"   {target_dir}")
        print(f"   ì§€ì› í˜•ì‹: {', '.join(SUPPORTED_EXTENSIONS)}")
        return None
    
    # íŒŒì¼ ëª©ë¡ í‘œì‹œ
    print("\nğŸ“‚ ì‚¬ìš© ê°€ëŠ¥í•œ ë³´ë„ìë£Œ:")
    print("-" * 50)
    for i, f in enumerate(press_files, 1):
        size_kb = f.stat().st_size / 1024
        file_icon = get_file_type_icon(f.suffix)
        print(f"  {i}. {f.stem} {file_icon}")
        print(f"     ({f.name}, {size_kb:.1f}KB)")
    
    # ë²ˆí˜¸ë¡œ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ì§€ì›)
    print("\nğŸ”¢ ì‚¬ìš©í•  ë³´ë„ìë£Œ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    print("   ğŸ’¡ ì—¬ëŸ¬ íŒŒì¼: 1,2,3 ë˜ëŠ” 1-3 ë˜ëŠ” all")
    try:
        choice_input = input(">>> ").strip().lower()
        
        selected_indices = []
        
        if choice_input == "all":
            # ì „ì²´ ì„ íƒ
            selected_indices = list(range(1, len(press_files) + 1))
        elif "-" in choice_input and "," not in choice_input:
            # ë²”ìœ„ ì„ íƒ (ì˜ˆ: 1-3)
            parts = choice_input.split("-")
            start, end = int(parts[0]), int(parts[1])
            selected_indices = list(range(start, end + 1))
        elif "," in choice_input:
            # ê°œë³„ ì„ íƒ (ì˜ˆ: 1,3,5)
            selected_indices = [int(x.strip()) for x in choice_input.split(",")]
        else:
            # ë‹¨ì¼ ì„ íƒ
            selected_indices = [int(choice_input)]
        
        # ìœ íš¨ì„± ê²€ì‚¬
        for idx in selected_indices:
            if idx < 1 or idx > len(press_files):
                print(f"âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤: {idx}")
                return None
        
        selected_files = [press_files[i - 1] for i in selected_indices]
        
    except ValueError:
        print("âŒ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1 ë˜ëŠ” 1,2,3 ë˜ëŠ” 1-3)")
        return None
    
    # ì„ íƒëœ íŒŒì¼ í‘œì‹œ
    if len(selected_files) == 1:
        print(f"\nâœ… ì„ íƒ: {selected_files[0].name}")
    else:
        print(f"\nâœ… ì„ íƒ: {len(selected_files)}ê°œ íŒŒì¼")
        for f in selected_files:
            print(f"   - {f.name}")
    
    # ëª¨ë“  íŒŒì¼ ì½ê¸° ë° í•©ì¹˜ê¸°
    all_texts = []
    for selected_file in selected_files:
        try:
            text = extract_text_from_file(selected_file)
            if text.strip():
                if len(selected_files) > 1:
                    # ì—¬ëŸ¬ íŒŒì¼ì¸ ê²½ìš° êµ¬ë¶„ì„  ì¶”ê°€
                    all_texts.append(f"\n\n===== {selected_file.name} =====\n\n{text}")
                else:
                    all_texts.append(text)
        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {selected_file.name} - {e}")
    
    if not all_texts:
        print("âŒ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    press_release = "\n".join(all_texts)
    print(f"ğŸ“„ ë³´ë„ìë£Œ ê¸¸ì´: {len(press_release):,} ê¸€ì")
    return press_release


class LoadingSpinner:
    """ë¡œë”© ìŠ¤í”¼ë„ˆ ì• ë‹ˆë©”ì´ì…˜"""
    def __init__(self, message="ì²˜ë¦¬ ì¤‘"):
        self.message = message
        self.running = False
        self.thread = None
    
    def start(self):
        self.running = True
        self.thread = threading.Thread(target=self._animate)
        self.thread.start()
    
    def _animate(self):
        frames = ['|', '/', '-', '\\']
        i = 0
        while self.running:
            print(f"\r  {frames[i % 4]} {self.message}...", end="", flush=True)
            time.sleep(0.2)
            i += 1
    
    def stop(self, success_msg="ì™„ë£Œ"):
        self.running = False
        if self.thread:
            self.thread.join()
        print(f"\r  [OK] {success_msg}" + " " * 20)

# ê²½ë¡œ ì„¤ì •
PERSONA_DIR = Path(__file__).parent / "output" / "personas"
PERSONA_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_DIR = Path.home() / "mcp-data" / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Word íŒŒì¼ ì „ìš© ì €ì¥ ìœ„ì¹˜
WORD_OUTPUT_DIR = Path(__file__).parent / "output" / "blog"
WORD_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Google Drive ìë™ ë™ê¸° í´ë”
GDRIVE_DIR = Path(r"G:\ë‚´ ë“œë¼ì´ë¸Œ\01_auto_system\02_Archive_to_blog")

# ì…ë ¥ í´ë” (ë³´ë„ìë£Œ í…ìŠ¤íŠ¸ íŒŒì¼ ë„£ëŠ” ê³³)
INPUT_DIR = Path(__file__).parent / "input" / "2_blog_writhing"
INPUT_DIR.mkdir(parents=True, exist_ok=True)


def list_personas():
    """ì €ì¥ëœ í˜ë¥´ì†Œë‚˜ ëª©ë¡"""
    personas = []
    for file_path in PERSONA_DIR.glob("*.json"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if "client_id" in data and "persona_analysis" in data:
                    personas.append({
                        "client_id": data["client_id"],
                        "client_name": data["client_name"],
                        "organization": data["organization"],
                        "formality": data["persona_analysis"]["formality_level"]["score"]
                    })
        except:
            pass
    return personas


def generate_blog_post(client_id: str, press_release: str, target_keywords: list = None):
    """ë¸”ë¡œê·¸ ê¸€ ìƒì„±"""
    
    print(f"\n{'='*50}")
    print(f"  AI ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì‹œì‘")
    print(f"{'='*50}")
    
    # í˜ë¥´ì†Œë‚˜ ìµœì‹  ë²„ì „ ë¡œë“œ
    result = load_latest_persona(client_id)
    if not result:
        print(f"âŒ í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {client_id}")
        return None
    
    persona_data, version, persona_file = result
    custom_prompt = persona_data.get("custom_prompt", "")
    client_name = persona_data.get("client_name", client_id)
    
    # blog_writing_configê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
    if "blog_writing_config" not in persona_data:
        persona_data["blog_writing_config"] = generate_default_blog_config(persona_data)
    
    print(f"  í˜ë¥´ì†Œë‚˜: {client_name} (v{version})")
    print(f"  ë³´ë„ìë£Œ: {len(press_release):,} ê¸€ì")
    print(f"{'='*50}\n")
    
    # Step 1: API ì—°ê²°
    print("[1/3] API ì—°ê²° ì¤€ë¹„")
    spinner = LoadingSpinner("Gemini AI ì—°ê²° ì¤‘")
    spinner.start()
    time.sleep(0.5)
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        spinner.stop("ì‹¤íŒ¨")
        print("âŒ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    client = genai.Client(api_key=api_key)
    spinner.stop("API ì—°ê²° ì™„ë£Œ")
    
    # í˜ë¥´ì†Œë‚˜ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
    persona_analysis = persona_data.get("persona_analysis", {})
    formality = persona_analysis.get("formality_level", {}).get("score", 5)
    writing_chars = persona_analysis.get("writing_characteristics", {})
    comm_style = persona_analysis.get("communication_style", {})
    green_flags = persona_analysis.get("green_flags", [])
    red_flags = persona_analysis.get("red_flags", [])
    
    # ê²©ì‹ë„ì— ë”°ë¥¸ ë§íˆ¬ ì„¤ì •
    if formality >= 8:
        sentence_ending = "í•©ì‡¼ì²´(~ìŠµë‹ˆë‹¤, ~ì…ë‹ˆë‹¤) ìœ„ì£¼ë¡œ ì‘ì„±"
        tone_desc = "ë§¤ìš° ê²©ì‹ìˆê³  ê³µì‹ì ì¸ í†¤"
        emoji_rule = "ì´ëª¨í‹°ì½˜ ì‚¬ìš© ìµœì†Œí™” ë˜ëŠ” ê¸ˆì§€"
    elif formality >= 6:
        sentence_ending = "í•´ìš”ì²´(~í•´ìš”, ~ì´ì—ìš”) 70% + í•©ì‡¼ì²´(~ìŠµë‹ˆë‹¤) 30% í˜¼ìš©"
        tone_desc = "ì •ì¤‘í•˜ë˜ ì¹œê·¼í•œ í†¤"
        emoji_rule = "ì ì ˆí•œ ì´ëª¨í‹°ì½˜ ì‚¬ìš© (^^, ~, ğŸ˜Š ë“±)"
    elif formality >= 4:
        sentence_ending = "í•´ìš”ì²´(~í•´ìš”) ìœ„ì£¼, ê°€ë” ë°˜ë§ ì„ì–´ë„ ë¬´ë°©"
        tone_desc = "í¸ì•ˆí•˜ê³  ì¹œê·¼í•œ í†¤"
        emoji_rule = "ì´ëª¨í‹°ì½˜ ììœ ë¡­ê²Œ ì‚¬ìš©"
    else:
        sentence_ending = "ë°˜ë§(~í•´, ~ì•¼) ë˜ëŠ” í•´ìš”ì²´ ììœ ë¡­ê²Œ ì‚¬ìš©"
        tone_desc = "ë§¤ìš° ìºì£¼ì–¼í•˜ê³  ì¹œêµ¬ê°™ì€ í†¤"
        emoji_rule = "ì´ëª¨í‹°ì½˜, 'ã…‹ã…‹', 'ã…ã…' ë“± ììœ ë¡­ê²Œ ì‚¬ìš©"
    
    # ë¬¸ì¥ ê¸¸ì´ ì„¤ì •
    sentence_length = writing_chars.get("sentence_length", "medium")
    if sentence_length == "short":
        length_guide = "ì§§ê³  ê°„ê²°í•œ ë¬¸ì¥ (15ì ë‚´ì™¸)"
    elif sentence_length == "long":
        length_guide = "ìƒì„¸í•˜ê³  ê¸´ ë¬¸ì¥ (30ì ì´ìƒ)"
    else:
        length_guide = "ì ë‹¹í•œ ê¸¸ì´ì˜ ë¬¸ì¥ (20ì ë‚´ì™¸)"
    
    # ì´ëª¨ì§€ ì‚¬ìš© ë¹ˆë„
    emoji_usage = writing_chars.get("emoji_usage", "moderate")
    if emoji_usage == "frequent":
        emoji_freq = "ë¬¸ë‹¨ë§ˆë‹¤ 1-2ê°œ ì´ìƒ ì´ëª¨í‹°ì½˜ í•„ìˆ˜"
    elif emoji_usage == "none":
        emoji_freq = "ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€"
    else:
        emoji_freq = "ì ì ˆíˆ ì´ëª¨í‹°ì½˜ ì‚¬ìš©"
    
    # í‚¤ì›Œë“œ ë¬¸ìì—´
    keywords_str = ", ".join(target_keywords) if target_keywords else ""
    
    # í˜ë¥´ì†Œë‚˜ ë§ì¶¤í˜• ë¸”ë¡œê·¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
    blog_prompt = f"""
{{
  "system_settings": {{
    "role": "{client_name} í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì‘ì„±ì (í˜ë¥´ì†Œë‚˜ ì¼ì¹˜ìœ¨ 100% ëª©í‘œ)",
    "objective": "ë³´ë„ìë£Œë¥¼ '{client_name}'ì˜ ê³ ìœ í•œ ë§íˆ¬ì™€ ìŠ¤íƒ€ì¼ë¡œ ì™„ë²½í•˜ê²Œ ë³€í™˜",
    "persona_enforcement_level": "CRITICAL (ì´ í˜ë¥´ì†Œë‚˜ ê°€ì´ë“œë¥¼ ë”°ë¥´ì§€ ì•Šì„ ê²½ìš° ì˜¤ë‹µìœ¼ë¡œ ê°„ì£¼í•¨)"
  }},
  "input_context": {{
    "press_release": "{press_release}",
    "target_keywords": ["{keywords_str}"],
    "persona_custom_request": "{custom_prompt}"
  }},
  "persona_profile": {{
    "name": "{client_name}",
    "organization": "{persona_data.get('organization', '')}",
    "formality_level": "{formality}/10 - {persona_analysis.get('formality_level', {}).get('description', '')}",
    "communication_style": {{
      "directness": "{comm_style.get('directness', 'balanced')}",
      "emotional_tone": "{comm_style.get('emotional_tone', 'neutral')}",
      "decision_making": "{comm_style.get('decision_making', 'independent')}"
    }}
  }},
  "strict_writing_rules": {{
    "tone_and_manner": {{
      "overall_tone": "{tone_desc}",
      "sentence_ending_rule": "{sentence_ending}",
      "sentence_length": "{length_guide}",
      "emoji_usage": "{emoji_freq}",
      "emotional_expression": "{comm_style.get('emotional_tone', 'neutral')} ê°ì • í‘œí˜„ ìœ ì§€"
    }},
    "must_follow_green_flags": {json.dumps(green_flags, ensure_ascii=False)},
    "must_avoid_red_flags": {json.dumps(red_flags, ensure_ascii=False)},
    "banned_characters": [
      "ìŠ¤ë§ˆíŠ¸ ë”°ì˜´í‘œ ê¸ˆì§€: " " ' ' ëŒ€ì‹  ì¼ë°˜ ë”°ì˜´í‘œ ì‚¬ìš©",
      "ë§ì¤„ì„í‘œ ê¸ˆì§€: ... ë˜ëŠ” â€¦ ì‚¬ìš© ê¸ˆì§€"
    ]
  }},
  "content_structure": {{
    "intro": "ë…ìì˜ ê´€ì‹¬ì„ ë„ëŠ” ì‹œì‘ (í˜ë¥´ì†Œë‚˜ í†¤ ìœ ì§€)",
    "body": "ë³´ë„ìë£Œ í•µì‹¬ ë‚´ìš©ì„ í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ë¡œ í’€ì–´ì„œ ì„¤ëª…",
    "outro": "ë§ˆë¬´ë¦¬ ë° í–‰ë™ ìœ ë„ (í˜ë¥´ì†Œë‚˜ íŠ¹ì„± ë°˜ì˜)"
  }},
  "formatting_rules": {{
    "header_style": "ì†Œì œëª©ì€ ã€Œ êº½ì‡  ê´„í˜¸ ã€ ë˜ëŠ” ## ë§ˆí¬ë‹¤ìš´ í—¤ë” ì‚¬ìš©",
    "emphasis_style": "í•µì‹¬ ë‚´ìš©ì€ **êµµê²Œ** ì²˜ë¦¬",
    "layout_style": "ê°€ë…ì„±ì„ ìœ„í•´ ì ì ˆí•œ ì¤„ë°”ê¿ˆ ì‚¬ìš©"
  }},
  "task_requirements": {{
    "seo_optimization": {{
      "title": "60ì ì´ë‚´, í‚¤ì›Œë“œ í¬í•¨, í´ë¦­ ìœ ë„í˜• ì œëª©",
      "meta_description": "155ì ì´ë‚´ ìš”ì•½",
      "keyword_integration": "í‚¤ì›Œë“œë¥¼ ë³¸ë¬¸ì— ìì—°ìŠ¤ëŸ½ê²Œ 3íšŒ ì´ìƒ í¬í•¨"
    }},
    "length": "1,500 ~ 2,000ì ë¶„ëŸ‰"
  }},
  "output_schema": {{
    "description": "ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œë§Œ ì¶œë ¥",
    "format": {{
      "title": "ë¸”ë¡œê·¸ ì œëª© String",
      "content": "Markdown í˜•ì‹ ë³¸ë¬¸ String (í˜ë¥´ì†Œë‚˜ í†¤ 100% ë°˜ì˜)",
      "tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3", "íƒœê·¸4", "íƒœê·¸5"],
      "meta_description": "155ì ì´ë‚´ String"
    }}
  }}
}}

**ì¤‘ìš”**: ìœ„ í˜ë¥´ì†Œë‚˜ í”„ë¡œí•„ê³¼ custom_requestë¥¼ ì² ì €íˆ ë”°ë¼ '{client_name}'ì˜ ë§íˆ¬ì™€ ìŠ¤íƒ€ì¼ë¡œë§Œ ì‘ì„±í•˜ì„¸ìš”.
(ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”)
"""
    
    # Step 2: AI ë¸”ë¡œê·¸ ìƒì„±
    print("\n[2/3] ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì¤‘")
    spinner = LoadingSpinner("AIê°€ í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ë¡œ ê¸€ì„ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤")
    spinner.start()
    
    try:
        response = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=blog_prompt
        )
        spinner.stop("ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì™„ë£Œ")
        
        # Step 3: ê²°ê³¼ ì²˜ë¦¬
        print("\n[3/3] íŒŒì¼ ì €ì¥ ì¤‘")
        spinner = LoadingSpinner("Word/Markdown íŒŒì¼ ìƒì„± ì¤‘")
        spinner.start()
        
        response_text = response.text
        
        # JSON ì¶”ì¶œ
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0]
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0]
        
        # ì˜ëª»ëœ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì •ë¦¬
        import re
        response_text = response_text.strip()
        # ì˜ëª»ëœ ë°±ìŠ¬ë˜ì‹œ ì´ìŠ¤ì¼€ì´í”„ ìˆ˜ì • (ì˜ˆ: \escape -> \\escape)
        response_text = re.sub(r'\\(?!["\\/bfnrtu])', r'\\\\', response_text)
        
        try:
            blog_content = json.loads(response_text)
        except json.JSONDecodeError as je:
            # ë§ˆì§€ë§‰ ì‹œë„: ë” ê³µê²©ì ì¸ ì •ë¦¬
            response_text = response_text.replace('\\"', '"').replace('\\n', '\n')
            response_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', response_text)
            blog_content = json.loads(response_text)
        
    except Exception as e:
        spinner.stop("ì˜¤ë¥˜ ë°œìƒ")
        print(f"\nâŒ ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
    
    # ì €ì¥
    output_id = f"BLOG_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    blog_data = {
        "output_id": output_id,
        "client_id": client_id,
        "client_name": client_name,
        "type": "blog",
        "content": blog_content,
        "created_at": datetime.now().isoformat()
    }
    
    # JSON ì €ì¥
    json_path = OUTPUT_DIR / f"{output_id}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(blog_data, f, ensure_ascii=False, indent=2)
    
    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë„ ìƒì„±
    md_path = OUTPUT_DIR / f"{output_id}.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# {blog_content['title']}\n\n")
        f.write(f"{blog_content['content']}\n\n")
        f.write(f"**íƒœê·¸:** {', '.join(blog_content['tags'])}\n")
    
    # Word íŒŒì¼ ìƒì„± (ë³„ë„ ìœ„ì¹˜ì— í˜ë¥´ì†Œë‚˜ëª…_ì œëª©_ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ)
    # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    safe_title = blog_content['title'][:30].replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_').strip()
    safe_client_name = client_name.replace(' ', '_')
    date_str = datetime.now().strftime('%Y%m%d')
    docx_filename = f"{safe_client_name}_{safe_title}_{date_str}.docx"
    docx_path = WORD_OUTPUT_DIR / docx_filename
    doc = Document()
    
    # ê¸°ë³¸ ìŠ¤íƒ€ì¼ì— í•œê¸€ í°íŠ¸ ì„¤ì •
    style = doc.styles['Normal']
    font = style.font
    font.name = 'ë§‘ì€ ê³ ë”•'
    font.size = Pt(11)
    
    # ì œëª© ì¶”ê°€
    title = doc.add_heading(blog_content['title'], level=1)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    # ì œëª©ì—ë„ í•œê¸€ í°íŠ¸ ì ìš©
    for run in title.runs:
        run.font.name = 'ë§‘ì€ ê³ ë”•'
    
    # ë³¸ë¬¸ ì¶”ê°€ (ë§ˆí¬ë‹¤ìš´ íŒŒì‹± ê°„ì†Œí™”)
    content = blog_content['content']
    paragraphs = content.split('\n\n')
    
    for para in paragraphs:
        if para.strip():
            # ì†Œì œëª© ì²˜ë¦¬ (ã€Œ ã€)
            if para.strip().startswith('ã€Œ') and para.strip().endswith('ã€'):
                p = doc.add_heading(para.strip()[1:-1].strip(), level=2)
                for run in p.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
            # êµ¬ë¶„ì„  ì²˜ë¦¬
            elif para.strip() == 'â€¢ â€¢ â€¢ â€¢ â€¢':
                p = doc.add_paragraph('â”€' * 30)
                p.alignment = WD_ALIGN_PARAGRAPH.CENTER
                for run in p.runs:
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
            # ì´ë¯¸ì§€ ìë¦¬ í‘œì‹œ
            elif para.strip().startswith('[ì´ë¯¸ì§€'):
                p = doc.add_paragraph(para.strip())
                p.alignment = WD_ALIGN_PARAGRAPH.CENTER
                run = p.runs[0]
                run.italic = True
                run.font.name = 'ë§‘ì€ ê³ ë”•'
            else:
                # ì¼ë°˜ ë³¸ë¬¸ - **êµµê²Œ** ì²˜ë¦¬
                p = doc.add_paragraph()
                parts = para.split('**')
                for i, part in enumerate(parts):
                    run = p.add_run(part)
                    run.font.name = 'ë§‘ì€ ê³ ë”•'
                    run.font.size = Pt(11)
                    if i % 2 == 1:  # í™€ìˆ˜ ì¸ë±ìŠ¤ëŠ” êµµê²Œ
                        run.bold = True
    
    # íƒœê·¸ ì¶”ê°€
    doc.add_paragraph()
    tags_para = doc.add_paragraph()
    tags_run = tags_para.add_run(f"íƒœê·¸: {', '.join(blog_content['tags'])}")
    tags_run.italic = True
    tags_run.font.name = 'ë§‘ì€ ê³ ë”•'
    
    # ë©”íƒ€ ì„¤ëª… ì¶”ê°€
    meta_para = doc.add_paragraph()
    meta_run = meta_para.add_run(f"ë©”íƒ€ ì„¤ëª…: {blog_content['meta_description']}")
    meta_run.italic = True
    meta_run.font.name = 'ë§‘ì€ ê³ ë”•'
    
    doc.save(str(docx_path))
    
    # Google Driveì—ë„ ë³µì‚¬ (í´ë”ê°€ ìˆìœ¼ë©´)
    gdrive_docx_path = None
    if GDRIVE_DIR.exists():
        import shutil
        try:
            gdrive_docx_path = GDRIVE_DIR / docx_filename
            shutil.copy2(docx_path, gdrive_docx_path)
            print(f"\r  [â˜ï¸] Google Drive ì—…ë¡œë“œ ì™„ë£Œ" + " " * 20)
        except Exception as e:
            print(f"\r  [âš ï¸] Google Drive ë³µì‚¬ ì‹¤íŒ¨: {e}")
    
    spinner.stop("íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    
    # ë²„ì „ ì •ë³´ ì¶”ê°€
    blog_data["version"] = version
    blog_data["client_id"] = client_id
    
    return blog_data, md_path, docx_path, gdrive_docx_path


def collect_feedback_and_upgrade(blog_data: Dict) -> bool:
    """ë¸”ë¡œê·¸ ìƒì„± í›„ í”¼ë“œë°± ìˆ˜ì§‘ ë° ìë™ ì—…ê·¸ë ˆì´ë“œ"""
    
    client_id = blog_data.get("client_id")
    version = blog_data.get("version", 1)
    output_id = blog_data.get("output_id")
    
    print("\n" + "=" * 60)
    print("ğŸ“Š ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì€ ì–´ë– ì…¨ë‚˜ìš”?")
    print("=" * 60)
    print("1. ì™„ë²½í•´ìš”! â­â­â­â­â­")
    print("2. ì¢‹ì•„ìš” â­â­â­â­")
    print("3. ê´œì°®ì•„ìš” â­â­â­")
    print("4. ì•„ì‰¬ì›Œìš” â­â­")
    print("5. ë‹¤ì‹œ ì¨ì£¼ì„¸ìš” â­")
    print("0. í”¼ë“œë°± ê±´ë„ˆë›°ê¸°")
    
    try:
        rating_input = input("\n>>> ").strip()
        
        if rating_input == "0":
            return False
        
        rating = int(rating_input)
        if rating < 1 or rating > 5:
            print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            return False
        
    except ValueError:
        print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return False
    
    # í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ë¡œë“œ
    feedback_data = get_feedback_history(client_id)
    
    # ìƒˆ í”¼ë“œë°± ì¶”ê°€
    feedback_entry = {
        "timestamp": datetime.now().isoformat(),
        "blog_id": output_id,
        "version": version,
        "rating": rating,
        "issues": [],
        "adjustments_made": {}
    }
    
    # í‰ì ì´ 4ì  ì´í•˜ë©´ ë¬¸ì œì  íŒŒì•…
    if rating <= 4:
        print("\nğŸ”§ ì–´ë–¤ ë¶€ë¶„ì´ ì•„ì‰¬ì› ë‚˜ìš”? (ë²ˆí˜¸ë¡œ ì„ íƒ, ì—¬ëŸ¬ ê°œ ê°€ëŠ¥: 1,2,3)")
        print("1. ë§íˆ¬/ì–´ë¯¸ê°€ ì•ˆ ë§ì•„ìš”")
        print("2. ë„ˆë¬´ ê¸¸ì–´ìš”")
        print("3. ë„ˆë¬´ ì§§ì•„ìš”")
        print("4. ì´ëª¨í‹°ì½˜ì´ ë„ˆë¬´ ë§ì•„ìš”")
        print("5. ì´ëª¨í‹°ì½˜ì´ ë„ˆë¬´ ì ì–´ìš”")
        print("6. ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ì–´ìš”")
        print("7. ë¬¸ì¥ì´ ë„ˆë¬´ ì§§ì•„ìš”")
        print("8. ì „ë¬¸ìš©ì–´ê°€ ì–´ë ¤ì›Œìš”")
        print("9. êµ¬ì¡°ê°€ ì´ìƒí•´ìš”")
        print("0. ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)")
        
        issues_input = input("\n>>> ").strip()
        
        if not issues_input:
            print("âŒ ë¬¸ì œì ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return False
        
        issue_map = {
            "1": "ë§íˆ¬/ì–´ë¯¸",
            "2": "ê¸€ì´ ë„ˆë¬´ ê¹",
            "3": "ê¸€ì´ ë„ˆë¬´ ì§§ìŒ",
            "4": "ì´ëª¨í‹°ì½˜ ê³¼ë‹¤",
            "5": "ì´ëª¨í‹°ì½˜ ë¶€ì¡±",
            "6": "ë¬¸ì¥ ë„ˆë¬´ ê¹",
            "7": "ë¬¸ì¥ ë„ˆë¬´ ì§§ìŒ",
            "8": "ì „ë¬¸ìš©ì–´ ì–´ë ¤ì›€",
            "9": "êµ¬ì¡° ë¬¸ì œ"
        }
        
        selected_issues = []
        for num in issues_input.split(","):
            num = num.strip()
            if num == "0":
                custom_issue = input("ê¸°íƒ€ ë¬¸ì œì ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                if custom_issue:
                    selected_issues.append(custom_issue)
            elif num in issue_map:
                selected_issues.append(issue_map[num])
        
        feedback_entry["issues"] = selected_issues
        
        # ìë™ ì¡°ì • ë¡œì§
        adjustments = {}
        
        for issue in selected_issues:
            if "ë§íˆ¬" in issue or "ì–´ë¯¸" in issue:
                # ê²©ì‹ë„ 1ë‹¨ê³„ ìƒí–¥ (ìµœëŒ€ 10)
                adjustments["formality_adjustment"] = "+1"
                
            elif "ë„ˆë¬´ ê¹" in issue:
                adjustments["content_rules.max_length"] = 1500
                adjustments["content_rules.paragraph_length"] = "short"
                
            elif "ë„ˆë¬´ ì§§" in issue:
                adjustments["content_rules.max_length"] = 2500
                adjustments["content_rules.paragraph_length"] = "medium"
                
            elif "ì´ëª¨í‹°ì½˜ ê³¼ë‹¤" in issue:
                adjustments["formatting.emoji_positions"] = ["intro", "outro"]
                
            elif "ì´ëª¨í‹°ì½˜ ë¶€ì¡±" in issue:
                adjustments["formatting.emoji_positions"] = ["intro", "body", "outro"]
                
            elif "ë¬¸ì¥ ë„ˆë¬´ ê¹" in issue:
                adjustments["tone_details.sentence_length"] = "short"
                
            elif "ë¬¸ì¥ ë„ˆë¬´ ì§§" in issue:
                adjustments["tone_details.sentence_length"] = "long"
                
            elif "ì „ë¬¸ìš©ì–´" in issue:
                adjustments["content_rules.technical_terms"] = "avoid"
                
            elif "êµ¬ì¡°" in issue:
                adjustments["structure.body_sections"] = 3
        
        feedback_entry["adjustments_made"] = adjustments
        
        # ì¡°ì • ì‚¬í•­ì´ ìˆìœ¼ë©´ ìƒˆ ë²„ì „ ìƒì„±
        if adjustments:
            print("\nğŸ”„ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ìƒˆ ë²„ì „ì„ ìƒì„±í• ê¹Œìš”? (Y/n): ", end="")
            create_new = input().strip().lower()
            
            if create_new != 'n':
                upgrade_reason = f"ì‚¬ìš©ì í”¼ë“œë°± (í‰ì : {rating}/5): " + ", ".join(selected_issues)
                new_persona = create_upgraded_version(client_id, adjustments, upgrade_reason)
                
                if new_persona:
                    print("\nâœ… ë‹¤ìŒ ë¸”ë¡œê·¸ë¶€í„° ê°œì„ ëœ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±ë©ë‹ˆë‹¤! ğŸ‰")
    
    else:
        print(f"\nâœ¨ ê°ì‚¬í•©ë‹ˆë‹¤! í˜„ì¬ ì„¤ì •(v{version})ì„ ìœ ì§€í•©ë‹ˆë‹¤.")
    
    # í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
    feedback_data["feedback_history"].append(feedback_entry)
    
    # í†µê³„ ì—…ë°ì´íŠ¸
    all_ratings = [f["rating"] for f in feedback_data["feedback_history"]]
    feedback_data["learning_stats"]["total_blogs"] = len(all_ratings)
    feedback_data["learning_stats"]["average_rating"] = round(sum(all_ratings) / len(all_ratings), 1)
    
    # ìµœê·¼ 5ê°œ vs ì „ì²´ í‰ê·  ë¹„êµ
    if len(all_ratings) >= 5:
        recent_avg = sum(all_ratings[-5:]) / 5
        overall_avg = sum(all_ratings) / len(all_ratings)
        feedback_data["learning_stats"]["improvement_trend"] = round(recent_avg - overall_avg, 1)
    
    # ê³µí†µ ì´ìŠˆ ì§‘ê³„
    common_issues = {}
    for f in feedback_data["feedback_history"]:
        for issue in f.get("issues", []):
            common_issues[issue] = common_issues.get(issue, 0) + 1
    feedback_data["learning_stats"]["common_issues"] = common_issues
    
    # ì €ì¥
    save_feedback_history(client_id, feedback_data)
    
    return True


def generate_blog_with_persona(client_id: str):
    """í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ í›„ ë°”ë¡œ ë¸”ë¡œê·¸ ìƒì„± (ì—°ê³„ í˜¸ì¶œìš©)"""
    print("\n" + "=" * 60)
    print("ğŸ“ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ë¸”ë¡œê·¸ ê¸€ ìƒì„±ê¸°")
    print("=" * 60)
    
    # ë³´ë„ìë£Œ ì„ íƒ (í´ë” ë° íŒŒì¼)
    press_release = select_press_release()
    if not press_release:
        return
    
    # SEO í‚¤ì›Œë“œ (ì„ íƒ)
    print("\nğŸ”‘ SEO í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„, ì—†ìœ¼ë©´ ì—”í„°):")
    keywords_input = input(">>> ").strip()
    keywords = [k.strip() for k in keywords_input.split(",")] if keywords_input else None
    
    # ë¸”ë¡œê·¸ ìƒì„±
    result = generate_blog_post(client_id, press_release, keywords)
    
    if result:
        blog_data, md_path, docx_path, gdrive_path = result
        blog = blog_data["content"]
        
        print("\n" + "=" * 60)
        print("âœ… ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì™„ë£Œ!")
        print("=" * 60)
        
        print(f"\nğŸ“Œ ì œëª©: {blog['title']}")
        print(f"ğŸ·ï¸ íƒœê·¸: {', '.join(blog['tags'])}")
        print(f"\nğŸ’¾ ì €ì¥ ìœ„ì¹˜:")
        print(f"   - Word: {docx_path}")
        if gdrive_path:
            print(f"   - â˜ï¸ Google Drive: {gdrive_path}")
        
        # í”¼ë“œë°± ìˆ˜ì§‘
        collect_feedback_and_upgrade(blog_data)
        
        # í´ë” ì—´ê¸° ì˜µì…˜
        print("\n" + "=" * 60)
        print("ğŸ“‚ ë¸”ë¡œê·¸ í´ë”ë¥¼ ì—¬ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ", end="")
        open_folder = input().strip().lower()
        if open_folder != 'n':
            subprocess.run(['explorer', str(WORD_OUTPUT_DIR)])
            print("   í´ë”ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ë¸”ë¡œê·¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


def main():
    print("=" * 60)
    print("ğŸ“ í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ë¸”ë¡œê·¸ ê¸€ ìƒì„±ê¸°")
    print("=" * 60)
    
    # í˜ë¥´ì†Œë‚˜ ëª©ë¡ í‘œì‹œ
    personas = list_personas()
    if not personas:
        print("\nâŒ ì €ì¥ëœ í˜ë¥´ì†Œë‚˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € run_persona_test.pyë¡œ í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í˜ë¥´ì†Œë‚˜:")
    print("-" * 50)
    for i, p in enumerate(personas, 1):
        print(f"  {i}. {p['client_name']}")
        print(f"     ({p['organization']}) - ê²©ì‹ë„: {p['formality']}/10")
    
    # í˜ë¥´ì†Œë‚˜ ì„ íƒ
    print("\nğŸ”¢ ì‚¬ìš©í•  í˜ë¥´ì†Œë‚˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    try:
        choice = int(input(">>> ").strip())
        selected = personas[choice - 1]
        client_id = selected["client_id"]
    except:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return
    
    print(f"\nâœ… ì„ íƒëœ í˜ë¥´ì†Œë‚˜: {selected['client_name']}")
    
    # ë³´ë„ìë£Œ ì„ íƒ (í´ë” ë° íŒŒì¼)
    press_release = select_press_release()
    if not press_release:
        return
    
    # SEO í‚¤ì›Œë“œ (ì„ íƒ)
    print("\nğŸ”‘ SEO í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì‰¼í‘œë¡œ êµ¬ë¶„, ì—†ìœ¼ë©´ ì—”í„°):")
    keywords_input = input(">>> ").strip()
    keywords = [k.strip() for k in keywords_input.split(",")] if keywords_input else None
    
    # ë¸”ë¡œê·¸ ìƒì„±
    result = generate_blog_post(client_id, press_release, keywords)
    
    if result:
        blog_data, md_path, docx_path, gdrive_path = result
        blog = blog_data["content"]
        
        print("\n" + "=" * 60)
        print("âœ… ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì™„ë£Œ!")
        print("=" * 60)
        
        print(f"\nğŸ“Œ ì œëª©: {blog['title']}")
        print(f"ğŸ·ï¸ íƒœê·¸: {', '.join(blog['tags'])}")
        print(f"\nğŸ’¾ ì €ì¥ ìœ„ì¹˜:")
        print(f"   - Word: {docx_path}")
        if gdrive_path:
            print(f"   - â˜ï¸ Google Drive: {gdrive_path}")
        
        # í”¼ë“œë°± ìˆ˜ì§‘
        collect_feedback_and_upgrade(blog_data)
        
        # í´ë” ì—´ê¸° ì˜µì…˜
        print("\n" + "=" * 60)
        print("ğŸ“‚ ë¸”ë¡œê·¸ í´ë”ë¥¼ ì—¬ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ", end="")
        open_folder = input().strip().lower()
        if open_folder != 'n':
            subprocess.run(['explorer', str(WORD_OUTPUT_DIR)])
            print("   í´ë”ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ë¸”ë¡œê·¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
